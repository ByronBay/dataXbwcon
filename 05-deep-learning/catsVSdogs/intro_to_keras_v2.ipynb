{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data-x](http://oi64.tinypic.com/o858n4.jpg)\n",
    "\n",
    "\n",
    "# Intro to Deep Learning with Keras\n",
    "\n",
    "#### Author: Alexander Fred Ojala\n",
    "\n",
    "_____\n",
    "\n",
    "# Why Keras\n",
    "Modular, powerful and intuitive Deep Learning python library built on TensorFlow, CNTK, Theano.\n",
    "* Minimalist, user-friendly interface\n",
    "* Integrated with Tensorflow (`tf.keras`)\n",
    "* Works on CPUs and GPUs\n",
    "* Open-source, developed and maintained by a community of contributors, and\n",
    "publicly hosted on github\n",
    "* Extremely well documented, lots of working examples: https://keras.io/\n",
    "* Very shallow learning curve â€”> it is by far one of the best tools for experimenting, both for beginners and experts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison: Deep Learning Framewroks\n",
    "Compile code down to the deep learning framework (i.e. takes longer to run). See comparison of speed for different DL frameworks:\n",
    "\n",
    "<img src='imgs/train_times.png' width=600px></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras backend\n",
    "\n",
    "We want Keras to use Tensorflow as a backend (should be default). If the warning above does not say:\n",
    "\n",
    "<div class='alert alert-danger'>**Using TensorFlow backend.**</div>\n",
    "\n",
    "Then open up the keras configuration file located in:\n",
    "\n",
    "`$HOME/.keras/keras.json` \n",
    "\n",
    "(On Windows replace `$HOME` with `%USERPROFILE%`)\n",
    "\n",
    "and change the entries in the JSON file to:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"floatx\": \"float32\",\n",
    "    \"epsilon\": 1e-07,\n",
    "    \"backend\": \"tensorflow\",\n",
    "    \"image_data_format\": \"channels_last\"\n",
    "}\n",
    "```\n",
    "\n",
    "After that restart your Kernel and run the code again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras \"Hello World\" on Iris\n",
    "\n",
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== =====\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR[:980])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode y\n",
    "import pandas as pd\n",
    "\n",
    "#y = pd.get_dummies(y).values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split, plus randomize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, test_size=0.4,\n",
    "                                                    random_state=1337,\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(90, 3)\n",
      "(60, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sequential model\n",
    "The simplest model in Keras is the Sequential model, a linear stack of layers.\n",
    "\n",
    "* **Sequential model** linear stack of layers: It allows us to build NNs like legos, by adding one layer on top of the other, and swapping layers\n",
    "\n",
    "* Graph: multi-input, multi-output, with arbitrary connections inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data structure in Keras is a model\n",
    "# The model is an object in which we organize layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model initialization\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential() # instantiate empty Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import layer classes and stack layers (in an NN model for example), by using `.add()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the input shape\n",
    "\n",
    "The model needs to know what input shape it should expect. For this reason, the first layer in a  Sequential model needs to receive information about its input shape. There are several possible ways to do this:\n",
    "\n",
    "* Pass an input_shape argument to the first layer. This is a shape tuple (a tuple of integers or `None` entries, where `None` indicates that any positive integer may be expected).\n",
    "* Some 2D layers, such as Dense, support the specification of their input shape via the argument  input_dim, and some 3D temporal layers support the arguments `input_dim` and `input_length`.\n",
    "\n",
    "\n",
    "**The following snippets are strictly equivalent:**\n",
    "> * `model.add(Dense(32, input_shape=(784,)))`\n",
    "> * `model.add(Dense(32, input_dim=784))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model contruction (architecture build computational graph)\n",
    "from keras.layers import Dense\n",
    "\n",
    "model.add( Dense(units=64, activation='relu', input_shape=(4,) ))\n",
    "model.add( Dense(units=3, activation='softmax') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation phase, specify learning process\n",
    "\n",
    "Run `.compile()` on the model to specify learning process.\n",
    "\n",
    "Before training a model, you need to configure the learning process, which is done via the  compile method. It receives three arguments:\n",
    "\n",
    "* **A loss function:** This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (such as `categorical_crossentropy` or `mse`), or it can be an objective function.\n",
    "* **An optimizer:** This could be the string identifier of an existing optimizer (such as `rmsprop`, `gradientdescent`, or `adagrad`), or an instance of the Optimizer class.\n",
    "* **(Optional) A list of metrics:** For any classification problem you will want to set this to `metrics=['accuracy']`. A metric could be the string identifier of an existing metric or a custom metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also specify our own optimizer or loss function (even build it ourselves)\n",
    "\n",
    "```python\n",
    "# or with we can specify loss function\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = SGD(lr=0.001, momentum = 0.9, nesterov=True),\n",
    "             metrics = ['accuracy'])\n",
    "```\n",
    "\n",
    "### Different optimizers and their trade-offs\n",
    "To read more about gradient descent optimizers, hyperparameters etc. This is a recommended reading: http://ruder.io/optimizing-gradient-descent/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5048 - acc: 0.2667\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - 0s 179us/step - loss: 1.3224 - acc: 0.2667\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - 0s 132us/step - loss: 1.1803 - acc: 0.2667\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - 0s 195us/step - loss: 1.0859 - acc: 0.3444\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - 0s 131us/step - loss: 1.0170 - acc: 0.6333\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - 0s 208us/step - loss: 0.9790 - acc: 0.5778\n",
      "Epoch 7/50\n",
      "90/90 [==============================] - 0s 228us/step - loss: 0.9498 - acc: 0.4667\n",
      "Epoch 8/50\n",
      "90/90 [==============================] - 0s 164us/step - loss: 0.9286 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "90/90 [==============================] - 0s 119us/step - loss: 0.9127 - acc: 0.5111\n",
      "Epoch 10/50\n",
      "90/90 [==============================] - 0s 181us/step - loss: 0.8971 - acc: 0.4778\n",
      "Epoch 11/50\n",
      "90/90 [==============================] - 0s 248us/step - loss: 0.8819 - acc: 0.4667\n",
      "Epoch 12/50\n",
      "90/90 [==============================] - 0s 102us/step - loss: 0.8674 - acc: 0.4444\n",
      "Epoch 13/50\n",
      "90/90 [==============================] - 0s 136us/step - loss: 0.8534 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "90/90 [==============================] - 0s 106us/step - loss: 0.8389 - acc: 0.6444\n",
      "Epoch 15/50\n",
      "90/90 [==============================] - 0s 113us/step - loss: 0.8250 - acc: 0.7111\n",
      "Epoch 16/50\n",
      "90/90 [==============================] - 0s 88us/step - loss: 0.8126 - acc: 0.7556\n",
      "Epoch 17/50\n",
      "90/90 [==============================] - 0s 95us/step - loss: 0.7981 - acc: 0.7778\n",
      "Epoch 18/50\n",
      "90/90 [==============================] - 0s 157us/step - loss: 0.7869 - acc: 0.7444\n",
      "Epoch 19/50\n",
      "90/90 [==============================] - 0s 115us/step - loss: 0.7742 - acc: 0.7333\n",
      "Epoch 20/50\n",
      "90/90 [==============================] - 0s 138us/step - loss: 0.7631 - acc: 0.7556\n",
      "Epoch 21/50\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.7533 - acc: 0.7778\n",
      "Epoch 22/50\n",
      "90/90 [==============================] - 0s 140us/step - loss: 0.7413 - acc: 0.8000\n",
      "Epoch 23/50\n",
      "90/90 [==============================] - 0s 133us/step - loss: 0.7313 - acc: 0.7333\n",
      "Epoch 24/50\n",
      "90/90 [==============================] - 0s 140us/step - loss: 0.7213 - acc: 0.7444\n",
      "Epoch 25/50\n",
      "90/90 [==============================] - 0s 106us/step - loss: 0.7119 - acc: 0.7556\n",
      "Epoch 26/50\n",
      "90/90 [==============================] - 0s 132us/step - loss: 0.7027 - acc: 0.8000\n",
      "Epoch 27/50\n",
      "90/90 [==============================] - 0s 110us/step - loss: 0.6934 - acc: 0.8111\n",
      "Epoch 28/50\n",
      "90/90 [==============================] - 0s 111us/step - loss: 0.6847 - acc: 0.8111\n",
      "Epoch 29/50\n",
      "90/90 [==============================] - 0s 119us/step - loss: 0.6770 - acc: 0.8333\n",
      "Epoch 30/50\n",
      "90/90 [==============================] - 0s 130us/step - loss: 0.6689 - acc: 0.8778\n",
      "Epoch 31/50\n",
      "90/90 [==============================] - 0s 135us/step - loss: 0.6599 - acc: 0.9000\n",
      "Epoch 32/50\n",
      "90/90 [==============================] - 0s 129us/step - loss: 0.6530 - acc: 0.8444\n",
      "Epoch 33/50\n",
      "90/90 [==============================] - 0s 99us/step - loss: 0.6451 - acc: 0.8333\n",
      "Epoch 34/50\n",
      "90/90 [==============================] - 0s 113us/step - loss: 0.6380 - acc: 0.8778\n",
      "Epoch 35/50\n",
      "90/90 [==============================] - 0s 97us/step - loss: 0.6301 - acc: 0.9000\n",
      "Epoch 36/50\n",
      "90/90 [==============================] - 0s 95us/step - loss: 0.6230 - acc: 0.9000\n",
      "Epoch 37/50\n",
      "90/90 [==============================] - 0s 89us/step - loss: 0.6156 - acc: 0.9000\n",
      "Epoch 38/50\n",
      "90/90 [==============================] - 0s 114us/step - loss: 0.6096 - acc: 0.9000\n",
      "Epoch 39/50\n",
      "90/90 [==============================] - 0s 115us/step - loss: 0.6022 - acc: 0.9111\n",
      "Epoch 40/50\n",
      "90/90 [==============================] - 0s 144us/step - loss: 0.5960 - acc: 0.9111\n",
      "Epoch 41/50\n",
      "90/90 [==============================] - 0s 153us/step - loss: 0.5895 - acc: 0.9111\n",
      "Epoch 42/50\n",
      "90/90 [==============================] - 0s 143us/step - loss: 0.5835 - acc: 0.9222\n",
      "Epoch 43/50\n",
      "90/90 [==============================] - 0s 147us/step - loss: 0.5772 - acc: 0.9333\n",
      "Epoch 44/50\n",
      "90/90 [==============================] - 0s 121us/step - loss: 0.5715 - acc: 0.9111\n",
      "Epoch 45/50\n",
      "90/90 [==============================] - 0s 139us/step - loss: 0.5654 - acc: 0.9000\n",
      "Epoch 46/50\n",
      "90/90 [==============================] - 0s 136us/step - loss: 0.5599 - acc: 0.8889\n",
      "Epoch 47/50\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.5546 - acc: 0.8889\n",
      "Epoch 48/50\n",
      "90/90 [==============================] - 0s 169us/step - loss: 0.5487 - acc: 0.9000\n",
      "Epoch 49/50\n",
      "90/90 [==============================] - 0s 139us/step - loss: 0.5437 - acc: 0.9111\n",
      "Epoch 50/50\n",
      "90/90 [==============================] - 0s 138us/step - loss: 0.5380 - acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f17d416f780>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model by iterating over the training data in batches\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 50, batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333492279053"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Evaluate the model Accuracy on test set\n",
    "model.evaluate(X_test, y_test, batch_size=60,verbose=False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on new data:\n",
    "\n",
    "class_probabilities = model.predict(X_test, batch_size=128)\n",
    "\n",
    "# gives output of the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09600657, 0.49913913, 0.40485424],\n",
       "       [0.8004235 , 0.14842539, 0.05115104],\n",
       "       [0.02900026, 0.40372407, 0.56727564],\n",
       "       [0.72372687, 0.19939676, 0.07687632],\n",
       "       [0.02247863, 0.36475503, 0.6127663 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probabilities[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras DNN on MNIST\n",
    "\n",
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "img_dim = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_dim)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_dim)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model to stack layers\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model contruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model constructor\n",
    "model = Sequential()\n",
    "# Add layers sequentially\n",
    "model.add(Dense(300, activation=tf.nn.leaky_relu, input_shape=(784,) ) )\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "# Second..\n",
    "model.add(Dense(200, activation=tf.nn.leaky_relu))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "# Third..\n",
    "model.add(Dense(100, activation=tf.nn.leaky_relu))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 316,810\n",
      "Trainable params: 316,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='adam', #chooses suitable learning rate for you.\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.3011 - acc: 0.9088\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1325 - acc: 0.9602\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0972 - acc: 0.9700\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=128,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.08080060906379949\n",
      "Test accuracy: 0.9758\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(3),history.history['acc'])\n",
    "plt.title('accuracy per iteration')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great accuracy for an ANN in so few training steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN in Keras\n",
    "## 99.5% accuracy on MNIST in 12 epochs\n",
    "\n",
    "Note this takes ~1hr to run on a CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# notice that we don't flatten image\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "#normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almost LeNet architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
